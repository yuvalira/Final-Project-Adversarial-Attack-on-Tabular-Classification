{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "I8DP9JBpBxVh",
        "eUvRvtdcF1hD",
        "ISJ3zwPUH7iM",
        "kdTLsgQmI5zQ"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuvalira/Final-Project-Adversarial-Attack-on-Tabular-Classification/blob/main/ATTACK/GBT_Attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wbQo0XQfBZR8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from scipy.stats import pointbiserialr\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, precision_score, recall_score, f1_score\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from random import sample\n",
        "from matplotlib.patches import FancyArrowPatch\n",
        "import matplotlib.patheffects as pe\n",
        "import torch\n",
        "from transformers import RobertaTokenizer, RobertaForMaskedLM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Adversarial Attack**"
      ],
      "metadata": {
        "id": "T53Bffin5rE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Get Model and Data from Git"
      ],
      "metadata": {
        "id": "I8DP9JBpBxVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Git clone\n",
        "REPO_URL = \"https://github.com/yuvalira/Final-Project-Adversarial-Attack-on-Tabular-Classification.git\"\n",
        "!git clone {REPO_URL}\n",
        "%cd Final-Project-Adversarial-Attack-on-Tabular-Classification\n",
        "\n",
        "# Read test dataset\n",
        "test_data = pd.read_csv('data/test_data.csv')\n",
        "print(f\"test_data loaded: {test_data.shape}\")\n",
        "\n",
        "# Read GBT model (sklearn)\n",
        "model_path = 'GBT/sklearn_GBT_model.joblib'\n",
        "assert os.path.exists(model_path), f\"Model file not found at {model_path}\"\n",
        "\n",
        "model_gbt = joblib.load(model_path)\n",
        "print(\"sklearn GBT model loaded successfully.\")\n",
        "\n",
        "# Load label encoders for decoding categorical features\n",
        "with open('data/label_encoders.pkl', 'rb') as f:\n",
        "    encoders = pickle.load(f)\n",
        "print(\"Label encoders loaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFsFro5mB3lR",
        "outputId": "8ec54744-fa9f-4260-8227-1ceb239fc23e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Final-Project-Adversarial-Attack-on-Tabular-Classification'...\n",
            "remote: Enumerating objects: 179, done.\u001b[K\n",
            "remote: Counting objects: 100% (179/179), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 179 (delta 75), reused 77 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (179/179), 3.65 MiB | 11.18 MiB/s, done.\n",
            "Resolving deltas: 100% (75/75), done.\n",
            "/content/Final-Project-Adversarial-Attack-on-Tabular-Classification/Final-Project-Adversarial-Attack-on-Tabular-Classification/Final-Project-Adversarial-Attack-on-Tabular-Classification/Final-Project-Adversarial-Attack-on-Tabular-Classification\n",
            "test_data loaded: (9769, 15)\n",
            "sklearn GBT model loaded successfully.\n",
            "Label encoders loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load fine-tuned model directly from Hugging Face Hub\n",
        "model_path = \"ETdanR/RoBERTa_FT_adult\"\n",
        "tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
        "model = RobertaForMaskedLM.from_pretrained(model_path)\n",
        "model.eval()\n",
        "\n",
        "# Define mask token info\n",
        "mask_token = tokenizer.mask_token\n",
        "mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "# Token IDs for income prediction (example IDs from your snippet)\n",
        "greater_than_id = 9312  # \"Greater\"\n",
        "less_than_id = 10862    # \"Less\""
      ],
      "metadata": {
        "id": "BYk1FiScG4LD"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_LM(df):\n",
        "    sentences = [\n",
        "        f\"age: {row['age']}, workclass: {row['workclass']}, education: {row['education']}, \"\n",
        "        f\"educational-num: {row['educational-num']}, marital-status: {row['marital-status']}, \"\n",
        "        f\"occupation: {row['occupation']}, relationship: {row['relationship']}, race: {row['race']}, \"\n",
        "        f\"gender: {row['gender']}, capital-gain: {row['capital-gain']}, capital-loss: {row['capital-loss']}, \"\n",
        "        f\"hours-per-week: {row['hours-per-week']}, native-country: {row['native-country']}, \"\n",
        "        f\"income: {mask_token} than 50k\"\n",
        "        for _, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    encoded = tokenizer(\n",
        "        sentences,\n",
        "        return_tensors='pt',\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**encoded)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    mask_positions = (encoded['input_ids'] == mask_token_id).nonzero(as_tuple=False)\n",
        "    predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "    results = []\n",
        "    for i in range(len(df)):\n",
        "        mask_index = mask_positions[mask_positions[:, 0] == i][0, 1]\n",
        "        predicted_token_id = predictions[i, mask_index].item()\n",
        "\n",
        "        if predicted_token_id == greater_than_id:\n",
        "            results.append(1)\n",
        "        elif predicted_token_id == less_than_id:\n",
        "            results.append(0)\n",
        "        else:\n",
        "            results.append(-1)\n",
        "\n",
        "    # Convert to numpy array with shape (batch_size,)\n",
        "    results_np = np.array(results, dtype=int)\n",
        "\n",
        "    print(\"predict called\")\n",
        "    return results_np"
      ],
      "metadata": {
        "id": "a_C8ZQkwGrku"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Prepare Data-Frames"
      ],
      "metadata": {
        "id": "eUvRvtdcF1hD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Correct Predictions and Incorrect Predictions datasets"
      ],
      "metadata": {
        "id": "hpTkmSKPTFOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COLUMN_NAME = 'income'\n",
        "\n",
        "# Create a copy of test_data\n",
        "test_data_attack = test_data.copy()\n",
        "\n",
        "# Prepare test features\n",
        "exclude_columns = [TARGET_COLUMN_NAME, 'fnlwgt']\n",
        "X_test = test_data.drop(columns=exclude_columns)\n",
        "y_true = test_data[TARGET_COLUMN_NAME].values\n",
        "\n",
        "# Predict class labels (0/1)\n",
        "y_pred = model_gbt.predict(X_test)\n",
        "\n",
        "# Create a new column for prediction correctness\n",
        "test_data_attack['correct_prediction'] = (y_true == y_pred)\n",
        "\n",
        "# Create datasets for correct and incorrect predictions\n",
        "correct_predictions_df = test_data_attack[test_data_attack['correct_prediction'] == True].drop(columns=['correct_prediction'])\n",
        "incorrect_predictions_df = test_data_attack[test_data_attack['correct_prediction'] == False].drop(columns=['correct_prediction'])\n",
        "\n",
        "print(f\"Correct predictions shape : {correct_predictions_df.shape}\")\n",
        "print(f\"Incorrect predictions shape : {incorrect_predictions_df.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wecfkxLzLc6E",
        "outputId": "cd47d37c-7736-40e2-d50d-dff3eda23819"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct predictions shape : (8572, 15)\n",
            "Incorrect predictions shape : (1197, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Create Correlation Dictionary\n",
        "\n",
        "We compute a correlation dictionary to guide and constrain the adversarial attack process.  \n",
        "For each feature and possible value, we calculate the correlation between the presence of that value and the target label.\n",
        "\n",
        "The correlation dictionary serves three key purposes:\n",
        "1. **Feature Filtering:** Only features with correlation above a defined threshold are considered for attack.\n",
        "2. **Feature Prioritization:** Features are sorted by correlation strength to guide the attack toward the most influential attributes first.\n",
        "3. **Categorical Attack Control:** For categorical features, value changes are limited to neighboring values based on their position in the correlation dictionary, avoiding random or unrealistic jumps between categories."
      ],
      "metadata": {
        "id": "ISJ3zwPUH7iM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_correlation_dict(df, target_column='income'):\n",
        "    \"\"\"\n",
        "    Create a dictionary of correlation values between feature values and the target class.\n",
        "    Used for driving adversarial attack modifications.\n",
        "    \"\"\"\n",
        "    correlation_dict = {}\n",
        "    target = df[target_column]\n",
        "    features = df.drop(columns=[target_column, 'fnlwgt'])\n",
        "\n",
        "    for col in features.columns:\n",
        "        value_corrs = {}\n",
        "\n",
        "        # Categorical or numerical feature\n",
        "        if features[col].dtype == 'object' or features[col].dtype.name == 'category':\n",
        "            unique_vals = features[col].unique()\n",
        "        else:\n",
        "            unique_vals = np.unique(features[col].values)\n",
        "\n",
        "        for val in unique_vals:\n",
        "            binary_vec = features[col].apply(lambda x: 1 if x == val else 0)\n",
        "            try:\n",
        "                corr, _ = pointbiserialr(binary_vec, target)\n",
        "            except Exception:\n",
        "                corr = 0\n",
        "\n",
        "            # Clean numpy types\n",
        "            if isinstance(val, (np.integer, np.int64)):\n",
        "                val = int(val)\n",
        "\n",
        "            value_corrs[val] = corr if not np.isnan(corr) else 0\n",
        "\n",
        "        # Sort values by correlation descending\n",
        "        correlation_dict[col] = dict(sorted(value_corrs.items(), key=lambda x: x[1], reverse=True))\n",
        "\n",
        "    return correlation_dict"
      ],
      "metadata": {
        "id": "h9cNV_kZiaWB"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_dict = create_correlation_dict(correct_predictions_df, target_column=\"income\")\n",
        "\n",
        "# Print correlation dict\n",
        "for feature, val_corrs in correlation_dict.items():\n",
        "    print(f\"\\nFeature: {feature}\")\n",
        "    for val, corr in val_corrs.items():\n",
        "        # If feature is categorical and encoder exists → decode value\n",
        "        if feature in encoders:\n",
        "            val = encoders[feature].inverse_transform([int(val)])[0]\n",
        "        print(f\"    {val}: {corr:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO-0NuUuplFi",
        "outputId": "3cc82034-57f3-4903-e2f8-076468da90e6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature: age\n",
            "    46: 0.0828\n",
            "    47: 0.0791\n",
            "    45: 0.0771\n",
            "    42: 0.0736\n",
            "    50: 0.0650\n",
            "    51: 0.0602\n",
            "    48: 0.0591\n",
            "    44: 0.0572\n",
            "    38: 0.0552\n",
            "    52: 0.0537\n",
            "    43: 0.0480\n",
            "    41: 0.0478\n",
            "    39: 0.0395\n",
            "    53: 0.0371\n",
            "    49: 0.0353\n",
            "    40: 0.0349\n",
            "    37: 0.0331\n",
            "    54: 0.0311\n",
            "    58: 0.0310\n",
            "    57: 0.0280\n",
            "    55: 0.0255\n",
            "    83: 0.0229\n",
            "    60: 0.0168\n",
            "    36: 0.0166\n",
            "    59: 0.0157\n",
            "    79: 0.0154\n",
            "    56: 0.0150\n",
            "    61: 0.0140\n",
            "    32: 0.0091\n",
            "    62: 0.0084\n",
            "    73: 0.0020\n",
            "    63: 0.0018\n",
            "    78: 0.0012\n",
            "    80: 0.0012\n",
            "    65: -0.0003\n",
            "    34: -0.0020\n",
            "    70: -0.0020\n",
            "    69: -0.0029\n",
            "    71: -0.0030\n",
            "    67: -0.0041\n",
            "    81: -0.0045\n",
            "    64: -0.0051\n",
            "    88: -0.0051\n",
            "    84: -0.0072\n",
            "    76: -0.0072\n",
            "    90: -0.0084\n",
            "    66: -0.0093\n",
            "    82: -0.0102\n",
            "    35: -0.0126\n",
            "    68: -0.0139\n",
            "    75: -0.0161\n",
            "    77: -0.0161\n",
            "    74: -0.0176\n",
            "    72: -0.0216\n",
            "    33: -0.0258\n",
            "    30: -0.0264\n",
            "    31: -0.0297\n",
            "    29: -0.0409\n",
            "    17: -0.0534\n",
            "    28: -0.0537\n",
            "    27: -0.0647\n",
            "    24: -0.0656\n",
            "    18: -0.0666\n",
            "    25: -0.0675\n",
            "    26: -0.0714\n",
            "    22: -0.0720\n",
            "    21: -0.0728\n",
            "    19: -0.0728\n",
            "    20: -0.0757\n",
            "    23: -0.0847\n",
            "\n",
            "Feature: workclass\n",
            "    Self-emp-inc: 0.1759\n",
            "    Federal-gov: 0.0459\n",
            "    Local-gov: 0.0398\n",
            "    State-gov: 0.0158\n",
            "    Self-emp-not-inc: 0.0059\n",
            "    Never-worked: -0.0051\n",
            "    Without-pay: -0.0088\n",
            "    Private: -0.0692\n",
            "    ?: -0.0838\n",
            "\n",
            "Feature: education\n",
            "    Masters: 0.2504\n",
            "    Bachelors: 0.2448\n",
            "    Prof-school: 0.2062\n",
            "    Doctorate: 0.1713\n",
            "    Assoc-acdm: 0.0235\n",
            "    Assoc-voc: 0.0020\n",
            "    Preschool: -0.0190\n",
            "    1st-4th: -0.0338\n",
            "    5th-6th: -0.0413\n",
            "    12th: -0.0488\n",
            "    7th-8th: -0.0549\n",
            "    9th: -0.0620\n",
            "    10th: -0.0778\n",
            "    Some-college: -0.0899\n",
            "    11th: -0.0906\n",
            "    HS-grad: -0.2048\n",
            "\n",
            "Feature: educational-num\n",
            "    14: 0.2504\n",
            "    13: 0.2448\n",
            "    15: 0.2062\n",
            "    16: 0.1713\n",
            "    12: 0.0235\n",
            "    11: 0.0020\n",
            "    1: -0.0190\n",
            "    2: -0.0338\n",
            "    3: -0.0413\n",
            "    8: -0.0488\n",
            "    4: -0.0549\n",
            "    5: -0.0620\n",
            "    6: -0.0778\n",
            "    10: -0.0899\n",
            "    7: -0.0906\n",
            "    9: -0.2048\n",
            "\n",
            "Feature: marital-status\n",
            "    Married-civ-spouse: 0.4820\n",
            "    Married-AF-spouse: 0.0077\n",
            "    Married-spouse-absent: -0.0509\n",
            "    Widowed: -0.0697\n",
            "    Separated: -0.0780\n",
            "    Divorced: -0.1411\n",
            "    Never-married: -0.3172\n",
            "\n",
            "Feature: occupation\n",
            "    Exec-managerial: 0.2918\n",
            "    Prof-specialty: 0.2448\n",
            "    Tech-support: 0.0356\n",
            "    Sales: 0.0279\n",
            "    Protective-serv: 0.0115\n",
            "    Armed-Forces: -0.0072\n",
            "    Priv-house-serv: -0.0330\n",
            "    Craft-repair: -0.0630\n",
            "    Farming-fishing: -0.0662\n",
            "    Transport-moving: -0.0722\n",
            "    ?: -0.0839\n",
            "    Adm-clerical: -0.0903\n",
            "    Handlers-cleaners: -0.0903\n",
            "    Machine-op-inspct: -0.0985\n",
            "    Other-service: -0.1570\n",
            "\n",
            "Feature: relationship\n",
            "    Husband: 0.4456\n",
            "    Wife: 0.1332\n",
            "    Other-relative: -0.0868\n",
            "    Unmarried: -0.1434\n",
            "    Own-child: -0.2101\n",
            "    Not-in-family: -0.2164\n",
            "\n",
            "Feature: race\n",
            "    White: 0.0976\n",
            "    Asian-Pac-Islander: 0.0091\n",
            "    Other: -0.0147\n",
            "    Amer-Indian-Eskimo: -0.0352\n",
            "    Black: -0.1031\n",
            "\n",
            "Feature: gender\n",
            "    Male: 0.2195\n",
            "    Female: -0.2195\n",
            "\n",
            "Feature: capital-gain\n",
            "    15024: 0.2320\n",
            "    7688: 0.2163\n",
            "    7298: 0.1941\n",
            "    99999: 0.1627\n",
            "    5178: 0.1321\n",
            "    3103: 0.1149\n",
            "    4386: 0.1018\n",
            "    8614: 0.0919\n",
            "    10520: 0.0795\n",
            "    14084: 0.0761\n",
            "    13550: 0.0761\n",
            "    20051: 0.0726\n",
            "    14344: 0.0726\n",
            "    27828: 0.0689\n",
            "    4787: 0.0562\n",
            "    25236: 0.0513\n",
            "    10605: 0.0513\n",
            "    7430: 0.0513\n",
            "    9386: 0.0513\n",
            "    6418: 0.0459\n",
            "    6514: 0.0397\n",
            "    11678: 0.0325\n",
            "    25124: 0.0229\n",
            "    15020: 0.0229\n",
            "    18481: 0.0229\n",
            "    2105: -0.0051\n",
            "    2936: -0.0051\n",
            "    3818: -0.0051\n",
            "    6767: -0.0051\n",
            "    1455: -0.0051\n",
            "    1797: -0.0051\n",
            "    2290: -0.0051\n",
            "    2346: -0.0051\n",
            "    3273: -0.0051\n",
            "    6723: -0.0051\n",
            "    114: -0.0051\n",
            "    1173: -0.0051\n",
            "    1831: -0.0051\n",
            "    2009: -0.0051\n",
            "    2329: -0.0051\n",
            "    7443: -0.0051\n",
            "    2036: -0.0051\n",
            "    2050: -0.0051\n",
            "    5721: -0.0051\n",
            "    1086: -0.0072\n",
            "    1151: -0.0072\n",
            "    1409: -0.0072\n",
            "    1471: -0.0072\n",
            "    3942: -0.0072\n",
            "    6497: -0.0072\n",
            "    1424: -0.0072\n",
            "    1848: -0.0072\n",
            "    2414: -0.0072\n",
            "    2964: -0.0072\n",
            "    3887: -0.0072\n",
            "    991: -0.0072\n",
            "    2635: -0.0072\n",
            "    3456: -0.0072\n",
            "    914: -0.0088\n",
            "    2463: -0.0088\n",
            "    3418: -0.0088\n",
            "    3471: -0.0088\n",
            "    3781: -0.0088\n",
            "    2907: -0.0088\n",
            "    4416: -0.0088\n",
            "    2580: -0.0102\n",
            "    2653: -0.0102\n",
            "    5455: -0.0102\n",
            "    1506: -0.0114\n",
            "    3464: -0.0114\n",
            "    4101: -0.0114\n",
            "    2176: -0.0114\n",
            "    2977: -0.0114\n",
            "    3674: -0.0114\n",
            "    2885: -0.0114\n",
            "    2829: -0.0125\n",
            "    3411: -0.0125\n",
            "    4508: -0.0135\n",
            "    2597: -0.0135\n",
            "    4865: -0.0135\n",
            "    2202: -0.0135\n",
            "    594: -0.0144\n",
            "    6849: -0.0144\n",
            "    4064: -0.0153\n",
            "    1055: -0.0153\n",
            "    2407: -0.0153\n",
            "    3908: -0.0153\n",
            "    3137: -0.0161\n",
            "    4650: -0.0169\n",
            "    2174: -0.0190\n",
            "    3325: -0.0222\n",
            "    5013: -0.0265\n",
            "    0: -0.3776\n",
            "\n",
            "Feature: capital-loss\n",
            "    1902: 0.1627\n",
            "    1887: 0.1526\n",
            "    1977: 0.1436\n",
            "    2415: 0.0795\n",
            "    1848: 0.0761\n",
            "    1564: 0.0513\n",
            "    2392: 0.0513\n",
            "    2559: 0.0513\n",
            "    2444: 0.0459\n",
            "    2824: 0.0325\n",
            "    3004: 0.0325\n",
            "    2246: 0.0325\n",
            "    2547: 0.0325\n",
            "    2174: 0.0229\n",
            "    2231: 0.0229\n",
            "    1485: 0.0219\n",
            "    2258: 0.0074\n",
            "    1816: -0.0051\n",
            "    2129: -0.0051\n",
            "    1340: -0.0051\n",
            "    2149: -0.0051\n",
            "    4356: -0.0051\n",
            "    323: -0.0051\n",
            "    1092: -0.0051\n",
            "    1617: -0.0051\n",
            "    2467: -0.0051\n",
            "    2603: -0.0051\n",
            "    625: -0.0051\n",
            "    974: -0.0051\n",
            "    1138: -0.0051\n",
            "    1429: -0.0051\n",
            "    2042: -0.0051\n",
            "    2206: -0.0051\n",
            "    3175: -0.0051\n",
            "    3770: -0.0051\n",
            "    3900: -0.0051\n",
            "    155: -0.0051\n",
            "    213: -0.0051\n",
            "    1510: -0.0051\n",
            "    1648: -0.0051\n",
            "    419: -0.0051\n",
            "    810: -0.0051\n",
            "    1380: -0.0072\n",
            "    1408: -0.0072\n",
            "    1668: -0.0072\n",
            "    1726: -0.0072\n",
            "    880: -0.0072\n",
            "    1411: -0.0072\n",
            "    1651: -0.0072\n",
            "    2163: -0.0072\n",
            "    2179: -0.0072\n",
            "    1573: -0.0088\n",
            "    1628: -0.0088\n",
            "    2377: -0.0088\n",
            "    2057: -0.0102\n",
            "    2205: -0.0102\n",
            "    1719: -0.0114\n",
            "    1762: -0.0114\n",
            "    2339: -0.0114\n",
            "    1721: -0.0114\n",
            "    1594: -0.0114\n",
            "    2051: -0.0125\n",
            "    1579: -0.0125\n",
            "    1590: -0.0125\n",
            "    1669: -0.0125\n",
            "    2002: -0.0125\n",
            "    1974: -0.0125\n",
            "    1980: -0.0125\n",
            "    1504: -0.0135\n",
            "    1741: -0.0144\n",
            "    1876: -0.0144\n",
            "    1672: -0.0161\n",
            "    2001: -0.0161\n",
            "    1740: -0.0190\n",
            "    1602: -0.0197\n",
            "    0: -0.1704\n",
            "\n",
            "Feature: hours-per-week\n",
            "    50: 0.1922\n",
            "    60: 0.1037\n",
            "    45: 0.0983\n",
            "    55: 0.0936\n",
            "    65: 0.0398\n",
            "    46: 0.0357\n",
            "    80: 0.0350\n",
            "    67: 0.0325\n",
            "    52: 0.0267\n",
            "    70: 0.0248\n",
            "    48: 0.0247\n",
            "    42: 0.0237\n",
            "    59: 0.0229\n",
            "    89: 0.0229\n",
            "    61: 0.0229\n",
            "    73: 0.0229\n",
            "    75: 0.0212\n",
            "    56: 0.0181\n",
            "    58: 0.0137\n",
            "    85: 0.0137\n",
            "    44: 0.0136\n",
            "    47: 0.0130\n",
            "    84: 0.0085\n",
            "    90: 0.0077\n",
            "    72: 0.0077\n",
            "    63: 0.0074\n",
            "    68: 0.0074\n",
            "    1: 0.0074\n",
            "    43: 0.0042\n",
            "    57: 0.0038\n",
            "    34: 0.0012\n",
            "    2: 0.0012\n",
            "    33: -0.0014\n",
            "    6: -0.0028\n",
            "    53: -0.0029\n",
            "    99: -0.0040\n",
            "    86: -0.0051\n",
            "    51: -0.0051\n",
            "    31: -0.0051\n",
            "    96: -0.0051\n",
            "    78: -0.0051\n",
            "    91: -0.0051\n",
            "    77: -0.0072\n",
            "    62: -0.0088\n",
            "    98: -0.0088\n",
            "    7: -0.0088\n",
            "    64: -0.0088\n",
            "    29: -0.0102\n",
            "    11: -0.0102\n",
            "    19: -0.0102\n",
            "    26: -0.0102\n",
            "    66: -0.0102\n",
            "    13: -0.0102\n",
            "    17: -0.0106\n",
            "    54: -0.0106\n",
            "    36: -0.0108\n",
            "    9: -0.0125\n",
            "    22: -0.0135\n",
            "    49: -0.0135\n",
            "    41: -0.0144\n",
            "    21: -0.0153\n",
            "    14: -0.0161\n",
            "    4: -0.0176\n",
            "    23: -0.0176\n",
            "    3: -0.0176\n",
            "    5: -0.0183\n",
            "    18: -0.0192\n",
            "    27: -0.0197\n",
            "    39: -0.0197\n",
            "    28: -0.0212\n",
            "    37: -0.0249\n",
            "    8: -0.0249\n",
            "    38: -0.0266\n",
            "    24: -0.0295\n",
            "    16: -0.0303\n",
            "    32: -0.0314\n",
            "    12: -0.0382\n",
            "    35: -0.0386\n",
            "    10: -0.0396\n",
            "    15: -0.0464\n",
            "    25: -0.0573\n",
            "    30: -0.0773\n",
            "    20: -0.0826\n",
            "    40: -0.0852\n",
            "\n",
            "Feature: native-country\n",
            "    India: 0.0384\n",
            "    England: 0.0323\n",
            "    United-States: 0.0282\n",
            "    Germany: 0.0278\n",
            "    Japan: 0.0266\n",
            "    Philippines: 0.0211\n",
            "    Taiwan: 0.0184\n",
            "    Italy: 0.0165\n",
            "    China: 0.0130\n",
            "    Canada: 0.0091\n",
            "    Cuba: 0.0049\n",
            "    France: 0.0038\n",
            "    Yugoslavia: 0.0038\n",
            "    ?: 0.0012\n",
            "    Hong: -0.0010\n",
            "    Ireland: -0.0029\n",
            "    Haiti: -0.0040\n",
            "    Iran: -0.0045\n",
            "    Ecuador: -0.0059\n",
            "    Hungary: -0.0072\n",
            "    Laos: -0.0088\n",
            "    Scotland: -0.0088\n",
            "    Thailand: -0.0102\n",
            "    Columbia: -0.0102\n",
            "    Poland: -0.0106\n",
            "    Greece: -0.0114\n",
            "    Nicaragua: -0.0114\n",
            "    Outlying-US(Guam-USVI-etc): -0.0114\n",
            "    Honduras: -0.0125\n",
            "    Trinadad&Tobago: -0.0125\n",
            "    El-Salvador: -0.0135\n",
            "    South: -0.0135\n",
            "    Peru: -0.0153\n",
            "    Portugal: -0.0161\n",
            "    Jamaica: -0.0204\n",
            "    Vietnam: -0.0210\n",
            "    Dominican-Republic: -0.0211\n",
            "    Puerto-Rico: -0.0212\n",
            "    Guatemala: -0.0222\n",
            "    Mexico: -0.0585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Adversarial Attack Generation\n",
        "\n",
        "This function generates adversarial examples by applying controlled perturbations to the input samples.  \n",
        "The attack follows a structured approach to efficiently search for minimal changes that will flip the model's prediction:\n",
        "\n",
        "1. **Input Selection:** Only correctly predicted samples are selected for the attack.\n",
        "2. **Feature Selection:** Features are prioritized and filtered based on the correlation dictionary.\n",
        "3. **Attack Loop:** For each sample:\n",
        "   - For **numeric features**, the value is perturbed by adding or subtracting a small pre-defined delta.\n",
        "   - For **categorical features**, the current value is replaced by neighboring values in the correlation dictionary (not random replacements).\n",
        "   - After each change, the model is queried. If the prediction flips, the attack stops for that sample.\n",
        "\n",
        "This method ensures that the attack remains realistic and focused on high-impact feature manipulations, avoiding excessive or implausible modifications."
      ],
      "metadata": {
        "id": "kdTLsgQmI5zQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_adversarial_attack(\n",
        "        df_test, model_gbt, correlation_dict, modelArch,\n",
        "        max_features_changed=3,\n",
        "        correlation_threshold=0.05, max_attempts=10):\n",
        "    # Declare bounds for numeric features\n",
        "    numeric_bounded_features = {\n",
        "        'age': 5,\n",
        "        'hours-per-week': 5,\n",
        "        'capital-gain': 1000,\n",
        "        'capital-loss': 1000,\n",
        "        'educational-num': 2,\n",
        "    }\n",
        "\n",
        "    adv_samples = []\n",
        "    success_count = 0\n",
        "    df_types = df_test.dtypes.to_dict()\n",
        "\n",
        "    df_test = df_test.sample(n=32, random_state=42)\n",
        "\n",
        "    # Prepare test set\n",
        "    exclude_columns = [TARGET_COLUMN_NAME, 'fnlwgt']\n",
        "    X_test = df_test.drop(columns=exclude_columns)\n",
        "    y_true = df_test[TARGET_COLUMN_NAME].values\n",
        "    y_pred_orig = model_gbt.predict(X_test) if modelArch == \"GBT\" else predict_LM(X_test)\n",
        "\n",
        "    # Prioritize features by correlation\n",
        "    priorities = []\n",
        "    for feature in correlation_dict.keys():\n",
        "        if feature == TARGET_COLUMN_NAME or feature not in df_test.columns:\n",
        "            continue\n",
        "        values = correlation_dict[feature].values()\n",
        "        max_corr = max(abs(v) for v in values if v is not None)\n",
        "        if max_corr >= correlation_threshold:\n",
        "            priorities.append((feature, max_corr))\n",
        "\n",
        "    priorities.sort(key=lambda x: x[1], reverse=True)\n",
        "    ordered_features = [f[0] for f in priorities]\n",
        "\n",
        "    for idx in range(len(df_test)):\n",
        "        original_input = df_test.iloc[[idx]]\n",
        "        original_label = original_input[TARGET_COLUMN_NAME].values[0]\n",
        "        current_sample = original_input.iloc[0].copy()\n",
        "        changed_features = set()\n",
        "        success = False\n",
        "        attempts = 0\n",
        "\n",
        "        while len(changed_features) < max_features_changed and attempts < max_attempts:\n",
        "            attempts += 1\n",
        "            current_X = pd.DataFrame([current_sample.drop(labels=[TARGET_COLUMN_NAME, 'fnlwgt'])])\n",
        "            current_pred = model_gbt.predict(current_X)[0] if modelArch == \"GBT\" else predict_LM(current_X)[0]\n",
        "\n",
        "            if current_pred != original_label:\n",
        "                success = True\n",
        "                break\n",
        "\n",
        "            candidate_samples = []\n",
        "            candidate_features = []\n",
        "\n",
        "            for feature in ordered_features:\n",
        "                if feature in changed_features:\n",
        "                    continue\n",
        "\n",
        "                current_value = current_sample[feature]\n",
        "\n",
        "                # Numeric feature\n",
        "                if feature in numeric_bounded_features:\n",
        "                    delta = numeric_bounded_features[feature]\n",
        "                    try:\n",
        "                        current_value = float(current_value)\n",
        "                        for new_val in [current_value + delta, max(0, current_value - delta)]:\n",
        "                            trial_sample = current_sample.copy()\n",
        "                            trial_sample[feature] = new_val\n",
        "                            candidate_samples.append(trial_sample)\n",
        "                            candidate_features.append(feature)\n",
        "                    except:\n",
        "                        continue\n",
        "\n",
        "                # Categorical feature\n",
        "                else:\n",
        "                    possible_vals = list(correlation_dict[feature].keys())\n",
        "                    current_value_int = int(current_value) if isinstance(current_value,\n",
        "                                                                         (np.integer, np.int64)) else current_value\n",
        "                    try:\n",
        "                        idx_val = possible_vals.index(current_value_int)\n",
        "                    except ValueError:\n",
        "                        continue\n",
        "\n",
        "                    neighbors = []\n",
        "                    if idx_val - 2 >= 0:\n",
        "                        neighbors.append(possible_vals[idx_val - 2])\n",
        "                    if idx_val + 2 < len(possible_vals):\n",
        "                        neighbors.append(possible_vals[idx_val + 2])\n",
        "                    if not neighbors and len(possible_vals) > 1:\n",
        "                        if idx_val > 0:\n",
        "                            neighbors.append(possible_vals[idx_val - 1])\n",
        "                        if idx_val < len(possible_vals) - 1:\n",
        "                            neighbors.append(possible_vals[idx_val + 1])\n",
        "\n",
        "                    for neighbor_val in neighbors:\n",
        "                        trial_sample = current_sample.copy()\n",
        "                        trial_sample[feature] = neighbor_val\n",
        "                        candidate_samples.append(trial_sample)\n",
        "                        candidate_features.append(feature)\n",
        "\n",
        "                if len(candidate_samples) >= 20:\n",
        "                    break\n",
        "\n",
        "            if not candidate_samples:\n",
        "                break\n",
        "\n",
        "            batch_X = pd.DataFrame(candidate_samples)[\n",
        "                [col for col in current_sample.index if col not in [TARGET_COLUMN_NAME, 'fnlwgt']]]\n",
        "            batch_preds = model_gbt.predict(batch_X) if modelArch == \"GBT\" else predict_LM(batch_X)\n",
        "\n",
        "            for i, pred in enumerate(batch_preds):\n",
        "                if int(pred) != original_label:\n",
        "                    current_sample = candidate_samples[i]\n",
        "                    changed_features.add(candidate_features[i])\n",
        "                    break\n",
        "\n",
        "        adv_samples.append(current_sample.astype(object))\n",
        "        if success:\n",
        "            success_count += 1\n",
        "\n",
        "    adv_df = pd.DataFrame(adv_samples).astype(df_types)\n",
        "\n",
        "    # Evaluation\n",
        "    adv_X = adv_df.drop(columns=[TARGET_COLUMN_NAME, 'fnlwgt'])\n",
        "    y_pred_adv = model_gbt.predict(adv_X) if modelArch == \"GBT\" else predict_LM(adv_X)\n",
        "\n",
        "    flipped = sum(y_pred_orig != y_pred_adv)\n",
        "    print(f\"\\n Attack success: {success_count}/{len(df_test)} ({(success_count / len(df_test)) * 100:.2f}%)\")\n",
        "    print(f\" Original accuracy: {accuracy_score(y_true, y_pred_orig):.2%}\")\n",
        "    print(f\" Adversarial accuracy: {accuracy_score(y_true, y_pred_adv):.2%}\")\n",
        "\n",
        "    return adv_df"
      ],
      "metadata": {
        "id": "TZbFPOz_QE6-"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we apply the adversarial attack on the set of correctly predicted test samples from the Gradient Boosted Trees (GBT) model.  \n",
        "\n",
        "This step generates the adversarial dataset (`adv_test_df`) used for further evaluation and analysis.\n"
      ],
      "metadata": {
        "id": "JJ6G2Sg3nVLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select subset of samples to attack\n",
        "samples_to_attack = correct_predictions_df.copy()\n",
        "\n",
        "# Run adversarial attack\n",
        "adv_test_df = generate_adversarial_attack(\n",
        "    df_test=samples_to_attack,\n",
        "    model_gbt=model_gbt,\n",
        "    correlation_dict=correlation_dict,\n",
        "    modelArch = \"LM\" # \"GBT\" or \"LM\"\n",
        ")\n",
        "\n",
        "print(f\"\\n Attack finished. Adversarial test set shape: {adv_test_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "NJ46XDmYQaBx",
        "outputId": "3609cf8a-134e-4fd6-b9ce-043461a8db2a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n",
            "predict called\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-0766f575d3d6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Run adversarial attack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m adv_test_df = generate_adversarial_attack(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples_to_attack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmodel_gbt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_gbt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-2dc07732abb0>\u001b[0m in \u001b[0;36mgenerate_adversarial_attack\u001b[0;34m(df_test, model_gbt, correlation_dict, modelArch, max_features_changed, correlation_threshold, max_attempts)\u001b[0m\n\u001b[1;32m    111\u001b[0m             batch_X = pd.DataFrame(candidate_samples)[\n\u001b[1;32m    112\u001b[0m                 [col for col in current_sample.index if col not in [TARGET_COLUMN_NAME, 'fnlwgt']]]\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0mbatch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_gbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmodelArch\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"GBT\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpredict_LM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-fdc08872f913>\u001b[0m in \u001b[0;36mpredict_LM\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1220\u001b[0m         )\n\u001b[1;32m   1221\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1222\u001b[0;31m         \u001b[0mprediction_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlm_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1224\u001b[0m         \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/models/roberta/modeling_roberta.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m         \u001b[0;31m# project back to size of vocabulary with bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1261\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Attack Evaluation"
      ],
      "metadata": {
        "id": "PjlgskNzEO7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_attack_changes(original_df, adversarial_df, label_column='income', verbose=True, max_samples_to_print=10):\n",
        "    \"\"\"\n",
        "    Analyze feature changes between original and adversarial samples.\n",
        "    Returns: list of differences per sample, and feature change counts.\n",
        "    Only prints up to max_samples_to_print changed samples for readability.\n",
        "    \"\"\"\n",
        "    feature_names = [f for f in original_df.columns if f not in [label_column, 'fnlwgt']]\n",
        "    change_counts = {feature: 0 for feature in feature_names}\n",
        "    total_samples = len(original_df)\n",
        "\n",
        "    all_diffs = []\n",
        "    printed_samples = 0\n",
        "\n",
        "    for idx in range(total_samples):\n",
        "        orig_row = original_df.iloc[idx]\n",
        "        adv_row = adversarial_df.iloc[idx]\n",
        "        diffs = {}\n",
        "        for feature in feature_names:\n",
        "            if orig_row[feature] != adv_row[feature]:\n",
        "                old_val = orig_row[feature]\n",
        "                new_val = adv_row[feature]\n",
        "\n",
        "                # decode categorical values back to original labels\n",
        "                if feature in encoders:\n",
        "                    try:\n",
        "                        old_val = encoders[feature].inverse_transform([int(old_val)])[0]\n",
        "                        new_val = encoders[feature].inverse_transform([int(new_val)])[0]\n",
        "                    except Exception:\n",
        "                        pass  # in case of any weird value, just keep as is\n",
        "\n",
        "                diffs[feature] = (old_val, new_val)\n",
        "                change_counts[feature] += 1\n",
        "\n",
        "        all_diffs.append(diffs)\n",
        "\n",
        "        if verbose and diffs and printed_samples < max_samples_to_print:\n",
        "            print(f\"\\nSample {idx}: {len(diffs)} feature(s) changed:\")\n",
        "            for feat, (old, new) in diffs.items():\n",
        "                print(f\"  {feat}: {old} → {new}\")\n",
        "            printed_samples += 1\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n--- Global Feature Change Statistics ---\")\n",
        "    for feature, count in change_counts.items():\n",
        "        print(f\"{feature}: changed in {count}/{total_samples} samples ({(count/total_samples)*100:.2f}%)\")\n",
        "\n",
        "    print(\"\\n Attack analysis completed.\")\n",
        "    return all_diffs, change_counts"
      ],
      "metadata": {
        "id": "iGf46z9Uj5NW"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_diffs, change_counts = analyze_attack_changes(\n",
        "    original_df=samples_to_attack,\n",
        "    adversarial_df=adv_test_df,\n",
        "    label_column='income'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "03K3xSiGj78O",
        "outputId": "646900eb-9ad5-4b11-ece9-ce05a8f61abb"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample 0: 7 feature(s) changed:\n",
            "  age: 56 → 52\n",
            "  education: HS-grad → 10th\n",
            "  educational-num: 9 → 6\n",
            "  marital-status: Divorced → Never-married\n",
            "  occupation: Other-service → Machine-op-inspct\n",
            "  relationship: Unmarried → Not-in-family\n",
            "  gender: Female → Male\n",
            "\n",
            "Sample 1: 6 feature(s) changed:\n",
            "  age: 25 → 49\n",
            "  workclass: Private → Self-emp-not-inc\n",
            "  marital-status: Married-civ-spouse → Divorced\n",
            "  occupation: Transport-moving → Sales\n",
            "  relationship: Own-child → Not-in-family\n",
            "  race: Other → White\n",
            "\n",
            "Sample 2: 5 feature(s) changed:\n",
            "  age: 43 → 25\n",
            "  workclass: Private → Local-gov\n",
            "  marital-status: Divorced → Never-married\n",
            "  relationship: Not-in-family → Own-child\n",
            "  capital-gain: 14344 → 0\n",
            "\n",
            "Sample 3: 6 feature(s) changed:\n",
            "  age: 32 → 22\n",
            "  education: HS-grad → 11th\n",
            "  educational-num: 9 → 7\n",
            "  marital-status: Married-civ-spouse → Never-married\n",
            "  occupation: Transport-moving → Adm-clerical\n",
            "  relationship: Husband → Not-in-family\n",
            "\n",
            "Sample 4: 8 feature(s) changed:\n",
            "  age: 20 → 25\n",
            "  education: HS-grad → Bachelors\n",
            "  educational-num: 9 → 13\n",
            "  occupation: Adm-clerical → Tech-support\n",
            "  relationship: Unmarried → Not-in-family\n",
            "  race: White → Black\n",
            "  gender: Female → Male\n",
            "  native-country: Germany → ?\n",
            "\n",
            "Sample 5: 5 feature(s) changed:\n",
            "  age: 54 → 25\n",
            "  marital-status: Divorced → Married-civ-spouse\n",
            "  occupation: Transport-moving → Tech-support\n",
            "  relationship: Not-in-family → Husband\n",
            "  hours-per-week: 45 → 40\n",
            "\n",
            "Sample 6: 9 feature(s) changed:\n",
            "  age: 25 → 33\n",
            "  education: Bachelors → 11th\n",
            "  educational-num: 13 → 7\n",
            "  marital-status: Married-civ-spouse → Never-married\n",
            "  occupation: Prof-specialty → Adm-clerical\n",
            "  relationship: Wife → Unmarried\n",
            "  race: White → Black\n",
            "  capital-loss: 1887 → 0\n",
            "  hours-per-week: 40 → 38\n",
            "\n",
            "Sample 7: 9 feature(s) changed:\n",
            "  age: 30 → 46\n",
            "  education: HS-grad → Some-college\n",
            "  educational-num: 9 → 10\n",
            "  marital-status: Never-married → Separated\n",
            "  occupation: Machine-op-inspct → Adm-clerical\n",
            "  relationship: Not-in-family → Unmarried\n",
            "  gender: Male → Female\n",
            "  hours-per-week: 50 → 40\n",
            "  native-country: Dominican-Republic → United-States\n",
            "\n",
            "Sample 8: 5 feature(s) changed:\n",
            "  age: 33 → 24\n",
            "  education: Some-college → Assoc-acdm\n",
            "  educational-num: 10 → 12\n",
            "  occupation: Adm-clerical → Exec-managerial\n",
            "  gender: Female → Male\n",
            "\n",
            "Sample 9: 8 feature(s) changed:\n",
            "  age: 42 → 25\n",
            "  workclass: Self-emp-not-inc → Local-gov\n",
            "  education: Some-college → Bachelors\n",
            "  educational-num: 10 → 13\n",
            "  marital-status: Married-civ-spouse → Never-married\n",
            "  occupation: Farming-fishing → Prof-specialty\n",
            "  relationship: Husband → Not-in-family\n",
            "  hours-per-week: 70 → 30\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "single positional indexer is out-of-bounds",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-7652efccd44e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m all_diffs, change_counts = analyze_attack_changes(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0moriginal_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples_to_attack\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0madversarial_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madv_test_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mlabel_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m<ipython-input-44-3c7957086c92>\u001b[0m in \u001b[0;36manalyze_attack_changes\u001b[0;34m(original_df, adversarial_df, label_column, verbose, max_samples_to_print)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0morig_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0madv_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madversarial_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdiffs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1751\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1752\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Robustness Comparison**\n",
        "\n",
        "Now, we will evaluate the model on both the original test set and the full attacked test set.  \n"
      ],
      "metadata": {
        "id": "yOqJjn51cwcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on original test set (before attack)\n",
        "X_original = test_data.drop(columns=['income', 'fnlwgt'])\n",
        "y_original = test_data['income']\n",
        "\n",
        "y_pred_original = model_gbt.predict(X_original)\n",
        "\n",
        "# Combine attacked + incorrect samples to create full attacked dataset\n",
        "full_attacked_test_data = pd.concat([adv_test_df, incorrect_predictions_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "X_attacked = full_attacked_test_data.drop(columns=['income', 'fnlwgt'])\n",
        "y_attacked = full_attacked_test_data['income']\n",
        "\n",
        "y_pred_attacked = model_gbt.predict(X_attacked)\n",
        "\n",
        "# Calculate metrics for original test set\n",
        "original_accuracy = accuracy_score(y_original, y_pred_original)\n",
        "original_precision = precision_score(y_original, y_pred_original)\n",
        "original_recall = recall_score(y_original, y_pred_original)\n",
        "original_f1 = f1_score(y_original, y_pred_original)\n",
        "\n",
        "# Calculate metrics for attacked test set\n",
        "attacked_accuracy = accuracy_score(y_attacked, y_pred_attacked)\n",
        "attacked_precision = precision_score(y_attacked, y_pred_attacked)\n",
        "attacked_recall = recall_score(y_attacked, y_pred_attacked)\n",
        "attacked_f1 = f1_score(y_attacked, y_pred_attacked)\n",
        "\n",
        "# Print comparison\n",
        "print(\"\\n Model Performance Comparison:\")\n",
        "print(f\" Original Accuracy: {original_accuracy:.4f} | Attacked Accuracy: {attacked_accuracy:.4f}\")\n",
        "print(f\" Original Precision: {original_precision:.4f} | Attacked Precision: {attacked_precision:.4f}\")\n",
        "print(f\" Original Recall: {original_recall:.4f} | Attacked Recall: {attacked_recall:.4f}\")\n",
        "print(f\" Original F1-Score: {original_f1:.4f} | Attacked F1-Score: {attacked_f1:.4f}\")\n",
        "\n",
        "# Accuracy drop\n",
        "drop = original_accuracy - attacked_accuracy\n",
        "print(f\"\\n Accuracy drop due to attack: {drop:.4f} ({drop*100:.2f}% drop)\")\n"
      ],
      "metadata": {
        "id": "JMfl_OyVbIkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROC Curve Comparison Before and After Attack**\n",
        "\n",
        "We compare the Receiver Operating Characteristic (ROC) curves of the model on the original test set and after the adversarial attack.  \n",
        "A lower ROC curve and AUC after attack indicates degradation of the model's classification ability."
      ],
      "metadata": {
        "id": "EjGplNf5dMxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Original test set\n",
        "X_original = test_data.drop(columns=['income', 'fnlwgt'])\n",
        "y_original = test_data['income']\n",
        "y_score_original = model_gbt.predict_proba(X_original)[:, 1]\n",
        "auc_original = roc_auc_score(y_original, y_score_original)\n",
        "fpr_original, tpr_original, _ = roc_curve(y_original, y_score_original)\n",
        "\n",
        "# Attacked test set\n",
        "X_attacked = full_attacked_test_data.drop(columns=['income', 'fnlwgt'])\n",
        "y_attacked = full_attacked_test_data['income']\n",
        "y_score_attacked = model_gbt.predict_proba(X_attacked)[:, 1]\n",
        "auc_attacked = roc_auc_score(y_attacked, y_score_attacked)\n",
        "fpr_attacked, tpr_attacked, _ = roc_curve(y_attacked, y_score_attacked)\n",
        "\n",
        "# Plot both curves\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_original, tpr_original, label=f\"Original Test Set (AUC = {auc_original:.4f})\", linewidth=2)\n",
        "plt.plot(fpr_attacked, tpr_attacked, label=f\"Attacked Test Set (AUC = {auc_attacked:.4f})\", linewidth=2, linestyle='--')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier (AUC = 0.5)\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.title(\"ROC Curve: Before vs After Adversarial Attack\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8viSTeDDdYfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve comparison shows a significant reduction in model performance under adversarial attack.  \n",
        "The AUC dropped from 0.9299 to 0.8351, demonstrating that the structured attack succeeded in reducing the model's ability to distinguish between income classes."
      ],
      "metadata": {
        "id": "zpfpljYueM5x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PCA**\n",
        "\n",
        "In this analysis, we applied PCA (Principal Component Analysis) to two datasets: one before an adversarial attack and one after.\n",
        "\n",
        "The purpose of PCA is to project high-dimensional data into a lower-dimensional space (2D) while preserving as much variance (information) as possible.\n",
        "This allows us to:\n",
        "\n",
        "\n",
        "*   Visually compare the distribution of data before and after the attack.\n",
        "*   Observe whether the attack caused meaningful changes in the data structure.\n",
        "*   Identify if there is a visual separation between the two datasets, which may indicate that the attack significantly altered the features."
      ],
      "metadata": {
        "id": "pjb5NwOUzmMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Map numeric labels to class names\n",
        "class_map = {\n",
        "    0: '<= 50k',\n",
        "    1: '> 50k'\n",
        "}\n",
        "\n",
        "# Define colors for each class name\n",
        "custom_colors = {\n",
        "    '<= 50k': 'lightsteelblue',  # light blue\n",
        "    '> 50k': 'dimgrey'  # gray\n",
        "}\n",
        "\n",
        "# Preprocess function\n",
        "def preprocess(df, label_column='income'):\n",
        "    raw_labels = df[label_column].values\n",
        "    labels = np.vectorize(class_map.get)(raw_labels)  # convert to class names\n",
        "    features = df.drop(columns=[label_column])\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "    return features_scaled, labels\n",
        "\n",
        "# Preprocess datasets\n",
        "X_original, y_original = preprocess(test_data, label_column='income')\n",
        "X_attacked, y_attacked = preprocess(full_attacked_test_data, label_column='income')\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_original_pca = pca.fit_transform(X_original)\n",
        "X_attacked_pca = pca.transform(X_attacked)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# Original\n",
        "for label in np.unique(y_original):\n",
        "    idx = y_original == label\n",
        "    axes[0].scatter(X_original_pca[idx, 0], X_original_pca[idx, 1],\n",
        "                    c=custom_colors[label], label=label, alpha=0.6)\n",
        "axes[0].set_title('Original Test Data')\n",
        "axes[0].set_xlabel('PC1')\n",
        "axes[0].set_ylabel('PC2')\n",
        "axes[0].legend(title='Income')\n",
        "\n",
        "# Attacked\n",
        "for label in np.unique(y_attacked):\n",
        "    idx = y_attacked == label\n",
        "    axes[1].scatter(X_attacked_pca[idx, 0], X_attacked_pca[idx, 1],\n",
        "                    c=custom_colors[label], label=label, alpha=0.6)\n",
        "axes[1].set_title('Attacked Test Data')\n",
        "axes[1].set_xlabel('PC1')\n",
        "axes[1].set_ylabel('PC2')\n",
        "axes[1].legend(title='Income')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q-dW9Diwzn55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class name map\n",
        "class_map = {0: '<= 50K', 1: '> 50K'}\n",
        "\n",
        "# Soft transition colors\n",
        "transition_colors = {\n",
        "    (0, 1): '#FF6F61',  # coral rose\n",
        "    (1, 0): '#6BA292'   # eucalyptus green\n",
        "}\n",
        "\n",
        "# Background colors\n",
        "background_colors = {\n",
        "    0: 'lightsteelblue',\n",
        "    1: 'dimgrey'\n",
        "}\n",
        "\n",
        "# Preprocess\n",
        "def preprocess(df, label_column='income'):\n",
        "    labels = df[label_column].values.astype(int)\n",
        "    features = df.drop(columns=[label_column])\n",
        "    scaler = StandardScaler()\n",
        "    features_scaled = scaler.fit_transform(features)\n",
        "    return features_scaled, labels\n",
        "\n",
        "# Prepare data\n",
        "X_original, y_original = preprocess(test_data)\n",
        "X_attacked, y_attacked = preprocess(full_attacked_test_data)\n",
        "\n",
        "# Changed samples\n",
        "changed_idx = np.where(y_original != y_attacked)[0]\n",
        "X_orig_changed = X_original[changed_idx]\n",
        "X_att_changed = X_attacked[changed_idx]\n",
        "y_from = y_original[changed_idx]\n",
        "y_to = y_attacked[changed_idx]\n",
        "\n",
        "# Select 5 from each transition\n",
        "transition_01 = np.where((y_from == 0) & (y_to == 1))[0]\n",
        "transition_10 = np.where((y_from == 1) & (y_to == 0))[0]\n",
        "selected_01 = sample(list(transition_01), min(5, len(transition_01)))\n",
        "selected_10 = sample(list(transition_10), min(5, len(transition_10)))\n",
        "selected_idx = selected_01 + selected_10\n",
        "\n",
        "X_orig_sel = X_orig_changed[selected_idx]\n",
        "X_att_sel = X_att_changed[selected_idx]\n",
        "y_from_sel = y_from[selected_idx]\n",
        "y_to_sel = y_to[selected_idx]\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_original_pca = pca.fit_transform(X_original)\n",
        "X_orig_pca_sel = pca.transform(X_orig_sel)\n",
        "X_att_pca_sel = pca.transform(X_att_sel)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 7))\n",
        "\n",
        "# Background\n",
        "for label in np.unique(y_original):\n",
        "    idx = y_original == label\n",
        "    ax.scatter(X_original_pca[idx, 0], X_original_pca[idx, 1],\n",
        "               c=background_colors[label], label=f\"{class_map[label]} (background)\",\n",
        "               alpha=0.2, s=30)\n",
        "\n",
        "# Arrows + points\n",
        "for i in range(len(selected_idx)):\n",
        "    x0, y0 = X_orig_pca_sel[i]\n",
        "    x1, y1 = X_att_pca_sel[i]\n",
        "    transition = (y_from_sel[i], y_to_sel[i])\n",
        "    color = transition_colors.get(transition, 'gray')\n",
        "\n",
        "    # Fancy arrow with outline\n",
        "    arrow = FancyArrowPatch((x0, y0), (x1, y1),\n",
        "                            arrowstyle='->',\n",
        "                            color=color,\n",
        "                            linewidth=1.5,\n",
        "                            mutation_scale=14,\n",
        "                            alpha=0.85,\n",
        "                            path_effects=[\n",
        "                                pe.Stroke(linewidth=1.5, foreground='black'),\n",
        "                                pe.Normal()\n",
        "                            ])\n",
        "    ax.add_patch(arrow)\n",
        "\n",
        "    # End point\n",
        "    ax.scatter(x1, y1, c=color, s=80, edgecolor='black', marker='o')\n",
        "\n",
        "# Final touches\n",
        "ax.set_title('PCA with Sample of Adversarial Shifts', fontsize=14)\n",
        "ax.set_xlabel('PC1')\n",
        "ax.set_ylabel('PC2')\n",
        "ax.legend(title='income')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "St1qS1co8XDI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}